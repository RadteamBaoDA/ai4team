# LiteLLM Proxy Environment Variables
# Copy this file to .env and configure for your environment

# ===== OLLAMA SERVERS =====
# Configure your Ollama server IP addresses and ports
OLLAMA_SERVER_1=192.168.1.2:11434
OLLAMA_SERVER_2=192.168.1.11:11434
OLLAMA_SERVER_3=192.168.1.20:11434

# ===== LITELLM PROXY =====
LITELLM_HOST=0.0.0.0
LITELLM_PORT=8000
LITELLM_WORKERS=4
LITELLM_LOG_LEVEL=INFO
CONFIG_PATH=./litellm_config.yaml

# ===== LOAD BALANCING =====
# Strategy: round_robin, least_busy (recommended), weighted
LOAD_BALANCING_STRATEGY=least_busy

# ===== LLM GUARD =====
# Enable/disable security scanning
GUARD_ENABLED=true
GUARD_INPUT_SCANNING=true
GUARD_OUTPUT_SCANNING=true

# ===== NGINX =====
NGINX_HOST=0.0.0.0
NGINX_PORT_HTTP=80
NGINX_PORT_HTTPS=443
NGINX_SERVER_NAME=llm.ai4team.vn
NGINX_WORKER_PROCESSES=auto

# ===== SSL/TLS =====
SSL_CERT_PATH=./ssl/cert.pem
SSL_KEY_PATH=./ssl/key.pem
SSL_ENABLED=true

# ===== RATE LIMITING =====
# Requests per second
RATE_LIMIT_API=10
RATE_LIMIT_CHAT=5
RATE_LIMIT_HEALTH=30

# ===== REDIS (CACHING) =====
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
CACHE_TTL=3600

# ===== LOGGING =====
LOG_LEVEL=INFO
LOG_FILE=./logs/litellm_proxy.log
LOG_FORMAT=json

# ===== TIMEOUTS =====
# Seconds
REQUEST_TIMEOUT=300
HEALTH_CHECK_TIMEOUT=5
CONNECTION_TIMEOUT=30

# ===== SECURITY =====
# Enable API key authentication (if needed)
AUTH_ENABLED=false
API_KEY_PREFIX=sk-

# ===== MONITORING =====
TRACK_COST=true
TRACK_LATENCY=true
TRACK_TOKEN_USAGE=true

# ===== DATABASE =====
DATABASE_URL=sqlite:///./litellm_proxy.db

# ===== DEBUG =====
DEBUG=false
PYTHONUNBUFFERED=1
LITELLM_LOGGING=INFO
