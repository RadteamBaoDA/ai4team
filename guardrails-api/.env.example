# LLM Guard API Environment Variables
# Copy this file to .env and modify as needed

# ==========================================
# Application Settings
# ==========================================
APP_NAME=LLM Guard API
APP_PORT=8000
LOG_LEVEL=INFO
LOG_JSON=true

# ==========================================
# Scan Settings
# ==========================================
# Stop scanning on first failure (faster)
SCAN_FAIL_FAST=true

# Timeout for prompt scanning (seconds)
SCAN_PROMPT_TIMEOUT=30

# Timeout for output scanning (seconds)
SCAN_OUTPUT_TIMEOUT=60

# Load models on first request (helps startup time)
LAZY_LOAD=true

# ==========================================
# Cache Settings
# ==========================================
# Maximum number of cached results
CACHE_MAX_SIZE=10000

# Cache TTL in seconds (1 hour)
CACHE_TTL=3600

# ==========================================
# Rate Limiting
# ==========================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_LIMIT=60/minute

# ==========================================
# Authentication
# ==========================================
# Set a Bearer token for API authentication
# Leave empty to disable authentication
AUTH_TOKEN=

# ==========================================
# Observability
# ==========================================
# Tracing exporter: console, otel_http, xray
TRACING_EXPORTER=console
# OpenTelemetry endpoint (for otel_http)
TRACING_OTEL_ENDPOINT=

# Metrics exporter: console, prometheus, otel_http
METRICS_TYPE=prometheus
# OpenTelemetry metrics endpoint
METRICS_ENDPOINT=

# ==========================================
# Local Models (Optional)
# ==========================================
# Path to local models directory
# MODELS_PATH=./models

# ==========================================
# Workers (for production)
# ==========================================
# Number of worker processes
APP_WORKERS=1
