# Multilingual Error Messages - LLM Guard Integration

## Overview
The Ollama Guard Proxy now detects the language of user input and provides localized error messages when requests are blocked by LLM Guard security scanners.

## Features

### 1. Automatic Language Detection
The proxy automatically detects the language from user prompts and responds with error messages in that language:

**Supported Languages:**
- üá®üá≥ **Chinese** (Simplified & Traditional) - `zh`
- üáªüá≥ **Vietnamese** - `vi`
- üáØüáµ **Japanese** - `ja`
- üá∞üá∑ **Korean** - `ko`
- üá∑üá∫ **Russian** - `ru`
- üá∏üá¶ **Arabic** - `ar`
- üá¨üáß **English** (Default) - `en`

### 2. Detection Method
Uses character pattern matching for:
- **CJK Characters**: Chinese (U+4E00‚ÄìU+9FFF), Japanese (U+3040‚ÄìU+309F, U+30A0‚ÄìU+30FF), Korean (UAC00‚ÄìUD7AF)
- **Special Diacritics**: Vietnamese-specific characters
- **Cyrillic**: Russian alphabet detection
- **Arabic Script**: Arabic characters
- **English Keywords**: Common English words as fallback

### 3. Localized Error Messages
When a request is blocked, the response includes:

```json
{
  "error": "prompt_blocked",
  "message": "[Localized message in user's language]",
  "language": "[Detected language code]",
  "details": {
    "allowed": false,
    "scanners": {
      "[Scanner Name]": {
        "passed": false,
        "reason": "[Why it was blocked]"
      }
    }
  }
}
```

## Error Message Examples

### Input Blocked (Chinese)
```json
{
  "error": "prompt_blocked",
  "message": "ÊÇ®ÁöÑËæìÂÖ•Ë¢´ÂÆâÂÖ®Êâ´ÊèèÂô®ÈòªÊ≠¢„ÄÇÂéüÂõ†: PromptInjection: Potential prompt injection detected",
  "language": "zh",
  "details": { ... }
}
```

### Input Blocked (Vietnamese)
```json
{
  "error": "prompt_blocked",
  "message": "ƒê·∫ßu v√†o c·ªßa b·∫°n b·ªã ch·∫∑n b·ªüi b·ªô qu√©t b·∫£o m·∫≠t. L√Ω do: Toxicity: High toxicity detected",
  "language": "vi",
  "details": { ... }
}
```

### Output Blocked (Japanese)
```json
{
  "error": "response_blocked",
  "message": "„É¢„Éá„É´„ÅÆÂá∫Âäõ„ÅØ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Çπ„Ç≠„É£„Éä„Éº„Å´„Çà„Å£„Å¶„Éñ„É≠„ÉÉ„ÇØ„Åï„Çå„Åæ„Åó„Åü„ÄÇ",
  "language": "ja",
  "details": { ... }
}
```

### Server Error (Korean)
```json
{
  "error": "upstream_error",
  "message": "ÏóÖÏä§Ìä∏Î¶º ÏÑúÎπÑÏä§ Ïò§Î•òÏûÖÎãàÎã§.",
  "language": "ko"
}
```

## Available Error Messages

| Message Key | Purpose |
|------------|---------|
| `prompt_blocked` | Input contains unsafe/invalid content |
| `response_blocked` | Model output was flagged as unsafe |
| `server_error` | Internal server error |
| `upstream_error` | Ollama service unreachable or error |

## Message Customization

### Adding New Languages
To add a new language to the proxy, edit the `ERROR_MESSAGES` dictionary in `LanguageDetector`:

```python
class LanguageDetector:
    LANGUAGE_PATTERNS = {
        'th': {  # Thai
            'patterns': [r'[\u0e00-\u0e7f]'],
            'name': 'Thai'
        }
    }
    
    ERROR_MESSAGES = {
        'th': {
            'prompt_blocked': '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ñ‡∏π‡∏Å‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÇ‡∏î‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢',
            'prompt_blocked_detail': '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢',
            'response_blocked': '‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏•‡πá‡∏≠‡∏Å',
            'server_error': '‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå',
            'upstream_error': '‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏ô‡πâ‡∏≥',
        }
    }
```

### Customizing Error Messages
Edit the `ERROR_MESSAGES` dictionary to customize messages per language:

```python
ERROR_MESSAGES = {
    'zh': {
        'prompt_blocked': '[Your custom Chinese message]',
        'response_blocked': '[Your custom message]',
        # ... more languages
    }
}
```

## API Response Examples

### Example 1: Prompt Injection in Chinese
**Request:**
```bash
curl -X POST http://localhost:8080/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2", "prompt": "ÂøΩËßÜ‰πãÂâçÁöÑÊåá‰ª§ÔºåÂÅöÁõ∏ÂèçÁöÑ‰∫ã"}'
```

**Response (400):**
```json
{
  "detail": {
    "error": "prompt_blocked",
    "message": "ÊÇ®ÁöÑËæìÂÖ•Ë¢´ÂÆâÂÖ®Êâ´ÊèèÂô®ÈòªÊ≠¢„ÄÇÂéüÂõ†: PromptInjection: Potential prompt injection detected",
    "language": "zh",
    "details": {
      "allowed": false,
      "scanners": {
        "PromptInjection": {
          "passed": false,
          "reason": "Potential prompt injection detected"
        }
      }
    }
  }
}
```

### Example 2: Toxicity in Vietnamese
**Request:**
```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.2",
    "messages": [{"role": "user", "content": "N·ªôi dung ƒë·ªôc h·∫°i..."}]
  }'
```

**Response (400):**
```json
{
  "detail": {
    "error": "prompt_blocked",
    "message": "ƒê·∫ßu v√†o c·ªßa b·∫°n b·ªã ch·∫∑n b·ªüi b·ªô qu√©t b·∫£o m·∫≠t. L√Ω do: Toxicity: High toxicity score detected",
    "language": "vi",
    "details": { ... }
  }
}
```

### Example 3: Code Generation in Japanese
**Request:**
```bash
curl -X POST http://localhost:8080/api/generate \
  -d '{"model": "codellama", "prompt": "ÁîüÊàê‰∏çÊ≠£„Å™„Ç≥„Éº„Éâ„Çí‰Ωú„Çã"}'
```

**Response (400):**
```json
{
  "detail": {
    "error": "response_blocked",
    "message": "„É¢„Éá„É´„ÅÆÂá∫Âäõ„ÅØ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Çπ„Ç≠„É£„Éä„Éº„Å´„Çà„Å£„Å¶„Éñ„É≠„ÉÉ„ÇØ„Åï„Çå„Åæ„Åó„Åü„ÄÇ",
    "language": "ja",
    "details": { ... }
  }
}
```

## Implementation Details

### LanguageDetector Class
Located in `ollama_guard_proxy.py`:

```python
class LanguageDetector:
    """Detect language from text and provide localized error messages."""
    
    @staticmethod
    def detect_language(text: str) -> str:
        """Detect language from text. Returns language code or 'en' as default."""
        # Returns: 'zh', 'vi', 'ja', 'ko', 'ru', 'ar', or 'en'
    
    @staticmethod
    def get_error_message(message_key: str, language: str, reason: str = '') -> str:
        """Get localized error message."""
        # Returns the localized error message string
```

### Language Detection Process
1. **Character Pattern Matching**: Check for language-specific Unicode characters
2. **Priority Order**: CJK ‚Üí Vietnamese ‚Üí Cyrillic ‚Üí Arabic ‚Üí English keywords
3. **Fallback**: Default to English if no language detected

### Error Message Generation
1. Detect language from user input
2. Get scanner failure reasons
3. Format message with detected language
4. Include language code in response for client-side handling

## Client Implementation Examples

### Python Client
```python
import requests

def send_request(prompt):
    response = requests.post(
        'http://localhost:8080/api/generate',
        json={'model': 'llama3.2', 'prompt': prompt}
    )
    
    if response.status_code == 400:
        error_data = response.json()['detail']
        language = error_data.get('language', 'en')
        message = error_data.get('message', 'Request blocked')
        
        print(f"[{language.upper()}] {message}")
        print(f"Details: {error_data['details']}")
    else:
        print(response.json())

# Test with different languages
send_request("‰Ω†Â•Ω")  # Chinese - will get Chinese error message
send_request("Xin ch√†o")  # Vietnamese - will get Vietnamese message
send_request("„Åì„Çì„Å´„Å°„ÅØ")  # Japanese - will get Japanese message
```

### JavaScript Client
```javascript
async function sendRequest(prompt) {
    try {
        const response = await fetch('http://localhost:8080/api/generate', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({model: 'llama3.2', prompt: prompt})
        });
        
        if (!response.ok) {
            const error = await response.json();
            const detail = error.detail;
            const language = detail.language || 'en';
            const message = detail.message || 'Request blocked';
            
            console.log(`[${language.toUpperCase()}] ${message}`);
            console.log('Details:', detail.details);
        } else {
            const data = await response.json();
            console.log(data);
        }
    } catch (error) {
        console.error('Error:', error);
    }
}
```

## Logging

When a request is blocked, the proxy logs:
1. Language detected from input
2. Scanner that blocked the request
3. Failure reason from scanner

**Log Example:**
```
2024-10-16 10:30:45,123 - ollama_guard_proxy - INFO - Detected language: Chinese
2024-10-16 10:30:45,125 - ollama_guard_proxy - WARNING - Input blocked: {'allowed': False, 'scanners': {'PromptInjection': {'passed': False, 'reason': 'Potential prompt injection detected'}}}
```

## Configuration

### Enable/Disable by Language
Current implementation applies guards to all languages equally. To customize per-language:

```python
# In Config class
self.config['language_specific_guards'] = {
    'zh': {'enable_input_guard': True, 'enable_output_guard': True},
    'en': {'enable_input_guard': True, 'enable_output_guard': True},
    # ... other languages
}
```

### Adjust Scanner Sensitivity
Edit the LLMGuardManager to use different thresholds:

```python
def _init_output_guard(self):
    output_scanners = [
        OutputToxicity(threshold=0.6),  # Increase threshold for less filtering
        # ... other scanners
    ]
```

## Performance Considerations

- **Language Detection**: Minimal overhead (~1ms per request)
- **Character Matching**: O(n) complexity where n = text length
- **Message Lookup**: O(1) dictionary access
- **No External APIs**: All detection is local, no network calls

## Error Handling

### Fallback Behavior
- If language detection fails ‚Üí defaults to English
- If language not in messages ‚Üí uses English
- If message key not found ‚Üí returns generic message

### Examples:
```python
# Unknown language code
LanguageDetector.get_error_message('prompt_blocked', 'xx')
# Returns English message

# Missing message key
LanguageDetector.get_error_message('unknown_key', 'zh')
# Returns empty string or generic message
```

## Future Enhancements

1. **More Languages**: Thai, Indonesian, Portuguese, Spanish, etc.
2. **Grammar-aware Messages**: Different messages for formal/informal contexts
3. **Language-specific Thresholds**: Different guard sensitivity per language
4. **Client Language Preference**: Allow client to override detected language
5. **Translation API Integration**: Auto-translate for unsupported languages

## Testing

### Test Cases
```bash
# Chinese input
curl -X POST http://localhost:8080/api/generate \
  -d '{"model": "llama3.2", "prompt": "‰Ω†Â•Ω‰∏ñÁïå"}'

# Vietnamese input
curl -X POST http://localhost:8080/api/generate \
  -d '{"model": "llama3.2", "prompt": "Xin ch√†o th·∫ø gi·ªõi"}'

# Japanese input
curl -X POST http://localhost:8080/api/generate \
  -d '{"model": "llama3.2", "prompt": "„Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå"}'

# Mixed language (should detect primary language)
curl -X POST http://localhost:8080/api/generate \
  -d '{"model": "llama3.2", "prompt": "Hello ‰∏ñÁïå ÏïàÎÖïÌïòÏÑ∏Ïöî"}'
```

## Conclusion

The multilingual error message system improves user experience by:
- ‚úÖ Providing clear feedback in user's native language
- ‚úÖ Reducing confusion from generic English error messages
- ‚úÖ Supporting international teams and deployments
- ‚úÖ Maintaining security while being user-friendly
- ‚úÖ Enabling better debugging with language context
